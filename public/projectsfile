<pre>   ___  ___  ____     _____________________
  / _ \/ _ \/ __ \__ / / __/ ___/_  __/ __/
 / ___/ , _/ /_/ / // / _// /__  / / _\ \  
/_/  /_/|_|\____/\___/___/\___/ /_/ /___/<br /><br /><a href="#fe">Frontend </a>| <a href="#be">Backend </a>| <a href="#fs">Full Stack </a>| <a href="#EE">Embedded/Electronics</a></pre>
<pre><a id="fe"></a><br />******************************************************
                    * Frontend *
******************************************************</pre>
<pre>________----------------------------------------________
\          <strong>Windows XP Inspired Personal Site          </strong> /
/_______----------------------------------------_______\<br /><br /><img src="https://i.imgur.com/01icVjy.png" alt="" width="439" height="258" /><br /><br /><strong>Project Overview<br /></strong>Transformed <a href="https://winxp.vercel.app/">ShizukuIchi's winXP demo</a> into a functional <br />personal portfolio, inspired by the first operating system <br />that sparked my passion for computers. This project marked <br />my first major frontend design and programming endeavor.<br /><br /><strong>Technologies Used<br /></strong>- React.js<br />- Node.js<br />- HTML / CSS<br />- Github Actions Pipeline<br />- DNS<br /><br /><strong>Key Achievements and Modifications<br /></strong> 1. Landing Page Enhancements<br />    - Integrated a functional landing page built with react into <br />      the Internet Explorer app<br />    - Based on <a href="https://github.com/tbakerx/react-resume-template">tbakersx's react-resume-template</a><br /> 2. Mobile Optimization<br />    - Implemented a dynamic viewfinder that scales appropriately <br />      based on screen size<br />    - Enhanced overall mobile functionality<br /> 3. Addition of Microsoft Word 2003<br />    - Faithfully recreated Microsoft Word 2003 to serve as a PDF<br />      wrapper for my resume<br />    - Note: Microsoft Office name, artwork, and trademark are<br />      property of Microsoft. <br /> 4. Notepad Functionality<br />    - Enhanced Notepad to display a stylized HTML detaiing my<br />      personal projects<br />    - Design inspired by early 2000s GameFaqs Guides<br /> 5. Github Actions and DNS Registration<br />    - Set up the build pipeline using Github Actions for both<br />      this Windows XP site and the landing page portfolio<br />    - Purchased the kokael.io domain<br /> 6. Customization and Optimization<br />    - Removed components and assets that didn't alligh with the <br />      personal site concept<br />    - Tailored the experience to focus on portfolio elements<br /><br /><strong>Outcome<br /></strong>Successfully created a unique, nostalgic, and functional <br />personal portfolio that showcases both technical skills <br />and creative problem-solving abilities. The project demonstrates <br />proficiency in React.js, frontend development, and UI/UX design <br />while paying homage to classic Windows XP aesthetics<strong>.<br /><br /><br /></strong></pre>
<pre><a id="be"></a>******************************************************
                    * Backend *
******************************************************</pre>
<pre>________-----------------------------------------------________
\          <strong>Computer Vision for Real-Time Aim Assist           </strong>/
/_______-----------------------------------------------_______\</pre>
<pre><strong>Project Overview<br /><br /></strong>For my Machine Learning Capstone, I developed a convolutional <br />neural network (CNN) designed to be nearly undetectable, using <br />OpenCV and PyTorch, to identify enemies on a player&rsquo;s screen in <br />the online game CS:GO. The algorithm then smoothly nudges the <br />player&rsquo;s mouse toward the detected enemies, creating a seamless <br />and human-like response.<br /><br /><strong>Technologies Used<br />- Computer Vision: </strong>OpenCV and Keras for image Processing<br />  and real-time video caputre<br />- <strong>Machine Learining: </strong>PyTorch for building, training, and fine<br />  tuning the CNN model.<br />- <strong>Data Visualization: </strong>Matplotlib for analyzing model performance<br />  and visualing data.<br />- <strong>Hardware Acceleration: </strong>NVIDIA RTX 3090 GPU leveraging CUDA for<br />  accelerated training and inference.<br />- <strong>Integration: </strong>HDMI Capture Card from Raspberri Pi Ambilight<br />  project for real-time feed aquisition, Bluetooth Dongle, and<br />  custom Logitech firmware for hardware integration.<br />- <strong>Programming Languages</strong>: Python for scripting, data handling, and<br />  model development. C++ for performance-critical sections of the<br />  code, particularly in mouse movement simulation.<br /><br /><strong>Methodology<br /></strong>I used the HDMI capture card to stream the laptop&rsquo;s screen <br />output into my RTX-powered desktop, which enabled both <br />accelerated training and real-time execution of the CNN. <br />The desktop handled the computationally intensive tasks <br />while the laptop displayed the game.<strong><br /><br />Data Collection<br /></strong>Given resource constraints, I manually captured and <br />labeled a dataset consisting of various player models <br />from the game. The dataset included images of enemy and <br />friendly players, which were processed using OpenCV to augment <br />and expand the dataset. Techniques such as downsampling and using <br />existing data setswere used to increase the diversity of the <br />training data.<strong><br /><br />Model Architecture<br /></strong>The CNN was designed with a series of convolutional layers, <br />each followed by ReLU activation functions and max-pooling <br />layers. The network was relatively shallow due to the limited <br />dataset, but included dropout layers to prevent overfitting. <br />The final layers consisted of fully connected layers, leading <br />to a softmax output, which determined the probability of a <br />detected enemy.<br /><br /><strong>Training Process<br /></strong>The training process leveraged CUDA for parallel processing <br />on the RTX GPU. I used a cross-entropy loss function and an <br />Adam optimizer, adjusting the learning rate dynamically based <br />on validation performance. Due to limited data, early <br />stopping was employed to prevent overfitting.<strong><br /><br />Real-Time Detection<br /></strong>To optimize real-time performance, the screen was divided <br />into three zones, inspired by foveated rendering techniques:<strong><br /> - </strong>The center of the screen processed at 12 frames per<br />   second (FPS), focusing on the most critical area where enemies<br />   are most likely to appear.<br /> - The intermediate zone, cover the area just outside the center,<br />   processed at 6 FPS.<br /> - The peripherial edges of the screen processed at 3 FPS,<br />   mimicking reduced attention similar to human peripherial vision.<br /><br /><img src="https://i.imgur.com/Mnew6Z0.png" alt="" width="486" height="274" /><br /><br /><strong>Mouse Movement Simulation<br /></strong>Upon detecting an enemy, the system calculated a smooth, <br />3rd-degree polynomial trajectory for the mouse movement. <br />This trajectory was designed to replicate human-like motion, <br />with natural acceleration and deceleration phases. The <br />calculated path was executed by the RTX desktop, which used <br />a Bluetooth dongle and custom Logitech firmware to control <br />the laptop&rsquo;s cursor.<strong><br /><br />Reaction Time Simulation:<br /></strong>To avoid detection, the system introduced a randomized <br />delay before initiating the mouse movement, based on a <br />high-level human reaction time of approximately 0.18 seconds. <br />This delay was randomized within a small range to prevent <br />the system from appearing too mechanical.<strong><br /><br />Result<br /></strong>The proof of concept successfully demonstrated the viability <br />of using a CNN for real-time enemy detection and cursor <br />manipulation in CS. Despite the promising results, the project <br />was limited by the small dataset and computational resources, <br />which restricted further optimization and refinement of the model.<strong><br />For ethical reasons I chose not to share the code / tampered <br />firmware.<br /><br /></strong><br /><br /><a id="fs"></a>****************************************************** <br />                    * Fullstack * <br />******************************************************<br /><br />___________----------------------------------------_________<br />\                       <strong>iOS App                   </strong>         / <br />/__________----------------------------------------________\<br /><br /></pre>
<pre>COMING SOON!<br /><br /><br /><br /><br /><br /><a id="EE"></a>****************************************************** <br />               * Embedded/Electronics * <br />******************************************************<br /><br />___________----------------------------------------_________<br />\                 A<strong>mbilight System for TV </strong>                 / <br />/__________----------------------------------------________\<br /><br /><strong>Project Objective<br /></strong>The goal of this project was to create a high-end, custom <br />wireless ambilight system for my OLED TV, pushing the boundaries <br />of visual immersion and technical integration. By combining <br />top-tier hardware with advanced software solutions, the project <br />aimed to achieve unparalleled color accuracy, responsiveness, <br />and integration with the TV's native systems.<br /><br /><strong>Technologies Used</strong><br />- Sony 65 Inch OLED TV (rooted to allow for custom software)<br />- <a href="https://quinled.info/quinled-dig-uno/">QuinLED-Dig-Uno controller board</a><br />  (I opted for this premade solution for the controller board<br />  because of the integrated level shifter, wifi, and safety<br />  features.)<br />- WS2815 addressable LED strips (90 LEDs/meter) (120+ inches)<br />- High-capacity 12V power supply<br />- Hyperion.ng .apk for screengrabbing TV content<br />- WLED 14.2 firmware flashed on QuinLED-Dig-Uno<br /><br /><strong>Key Achievements<br /></strong> 1. High-Density LED Implementation<br />    - Utilized WS2815 LED strips with 90 LEDs/meter for superior <br />      resolution<br />    - Achieved smooth color transitions accurate representation<br />      of on-screen SDR, HDR, and Dolby Vision content.<br /> 2. Advanced Controller Integration<br />    - Successfully implemented QuinLED-Dig-Uno for reliable and<br />      efficient LED control<br />    - Leveraged the controller's built-in Wi-Fi to connect to<br />      Hyperion.NG running on the TV<br /> 3. TV Root and Software Integration:<br />    - Successfully rooted my Sony TV running Google software,<br />      enabling deep system integration<br />    - Installed and optimzied Hyperion.NG directly on TV for <br />      minimal latency<br /> 4. High Dynamic Range (HDR) Comparibility<br />    - Ensured full compatibility with HDR10, HDR10+, and Dolby<br />      Vision content<br />    - Calibrated the LEDs to accurately represent extended color<br />      gamuts<br /> 5. Low Latency Performance<br />    - Achieved real-time synchronization between on-screen content<br />      and ambient lighting<br /> 6. Power Management<br />    - Implemented sufficient power delivery for the high-density<br />      LED setup (105+ Watts)<br />    - Ensured stable operation even during peak brightness scenarios<br /><br /><strong>Results</strong><br />The completed advanced ambilight system significantly enhanced <br />my home theater setup, surpassing commercially avaiable solutions<br />for less money.<br /><br /><img src="https://i.imgur.com/UaBFrhW.gif" alt="" width="500" height="345" /></pre>
